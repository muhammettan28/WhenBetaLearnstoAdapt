This repository accompanies the article "When Œ≤ Learns to Adapt: Stabilizing Variational Ensembles for Visual Malware Detection" and provides minimal, reproducible examples of the five models described in the study.
Each script in the /src directory corresponds to a distinct model configuration, incrementally extending the baseline CNN architecture with feature-fusion, autoencoding, and adaptive Œ≤-VAE mechanisms.

Repository Structure

	src/

   		‚îú‚îÄ‚îÄ model1.py

   		‚îú‚îÄ‚îÄ model2.py

   		‚îú‚îÄ‚îÄ model3.py

   		‚îú‚îÄ‚îÄ model4.py

   		‚îú‚îÄ‚îÄ model5.py


	data/sample_malimg/

	README.md




‚öôÔ∏è Model Descriptions

Model 1 ‚Äî Baseline CNNs (Single Backbone Evaluation)

This model trains individual pre-trained convolutional networks (VGG16, VGG19, Xception, ResNet50, ConvNeXtLarge) separately on the visual malware datasets.
It establishes a baseline for per-architecture performance and serves as the foundation for the feature-fusion ensemble.
Each CNN is fine-tuned with frozen ImageNet weights, global average pooling, and fully connected classifier layers.

‚∏ª

Model 2 ‚Äî Feature Fusion Ensemble

Model 2 integrates the feature representations of multiple CNN backbones through concatenation.
Each backbone acts as a parallel feature extractor, and their flattened outputs are merged to form an extended feature space.
This approach enhances feature diversity and improves multi-scale representation learning across malware families.

‚∏ª

Model 3 ‚Äî Autoencoder-Enhanced Feature Compression

In this configuration, the fused feature vectors obtained from Model 2 are passed through a symmetric autoencoder block.
The encoder compresses the high-dimensional feature space into latent representations (tested with 32, 128, 256 dimensions), while the decoder reconstructs them to enforce information consistency.
This design evaluates how latent-space compression affects generalization and classification stability.

‚∏ª

Model 4 ‚Äî Fixed-Œ≤ Variational Autoencoder (Œ≤-VAE)

Model 4 replaces the deterministic autoencoder with a variational counterpart, introducing a fixed Œ≤ coefficient in the KL-divergence term to control the regularization strength.
Three fixed Œ≤ values (0.05, 0.01, 0.001) are tested across different latent sizes.
While the fixed-Œ≤ approach promotes disentanglement, it often suffers from posterior collapse and unstable loss dynamics as the feature-space dimensionality increases.

‚∏ª

Model 5 ‚Äî Annealing-Based Œ≤-VAE (Proposed Model)

Model 5 extends Model 4 with an annealing mechanism that dynamically increases Œ≤ during training, preventing abrupt regularization in early epochs.
This adaptive scheduling stabilizes training, balances reconstruction and regularization terms, and mitigates the exploding-loss problem observed in fixed-Œ≤ configurations.
Additional refinements include:
	‚Ä¢	Label smoothing (Œµ = 0.05) to improve calibration across heterogeneous datasets.
	‚Ä¢	Gradient clipping (clipnorm = 1.0) to control gradient explosion.
	‚Ä¢	ReduceLROnPlateau scheduler for adaptive learning rate decay.
	‚Ä¢	Increased dropout (0.3) for stronger regularization in large feature spaces.

‚∏ª
üîó License

This code is released for academic and research purposes only under the MIT License.
